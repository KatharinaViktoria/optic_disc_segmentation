{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from monai.data import Dataset, list_data_collate # , decollate_batch\n",
    "# from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    AsChannelFirst,\n",
    "    AsChannelLast, \n",
    "    RandFlip,\n",
    "    ToTensor,\n",
    "    Resize\n",
    "    # EnsureType,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "from monai.data import ArrayDataset, create_test_image_2d # , decollate_batch\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "from monai.utils import set_determinism\n",
    "from monai.utils.misc import first\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all parameters:\n",
    "nr_train_samples = 500\n",
    "nr_val_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/kvh4/optic_disc/data/REFUGE-2/REFUGE2-Training/resized_data/non_glaucoma/images\"\n",
    "images = os.listdir(image_dir)\n",
    "image_paths = [os.path.join(image_dir, i) for i in images]\n",
    "\n",
    "gt_dir = \"/kvh4/optic_disc/data/REFUGE-2/REFUGE2-Training/resized_data/non_glaucoma/ground_truth\"\n",
    "gt_paths = [os.path.join(gt_dir, i[:-4]+\".bmp\") for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = image_paths[:nr_train_samples]\n",
    "training_gt = gt_paths[:nr_train_samples]\n",
    "\n",
    "validation_images = image_paths[nr_train_samples:(nr_train_samples+nr_val_samples)]\n",
    "validation_gt = gt_paths[nr_train_samples:(nr_train_samples+nr_val_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = image_paths[:10]\n",
    "test_gt = gt_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training transformations (separately for input and gt)\n",
    "test_imtransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         RandFlip(spatial_axis=1, prob=.5),\n",
    "         RandFlip(spatial_axis=0, prob=.5),\n",
    "         RandRotate(range_x=15, prob=0.3, keep_size=True),\n",
    "         ScaleIntensity(),\n",
    "         ToTensor()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "test_gttransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         RandFlip(spatial_axis=1, prob=.5),\n",
    "         RandFlip(spatial_axis=0, prob=.5),\n",
    "         RandRotate(range_x=15, prob=0.3, keep_size=True),\n",
    "         ToTensor(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "         # Lambda(lambda x: x[0,:,:]),\n",
    "         # AddChannel(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ArrayDataset(test_images, test_imtransforms, test_gt, test_gttransforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=6) #, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(check_data[1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(6,3, figsize=(12,20))\n",
    "for i in range(6):\n",
    "    plt.subplot(6,3,i*3+1)\n",
    "    image = np.zeros((check_data[0][i][0].shape[0], check_data[0][i][0].shape[1],3))\n",
    "    for c in range(3):\n",
    "        image[:,:,c] = check_data[0][i][c]\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(6,3,i*3+2)\n",
    "    plt.imshow(check_data[1][i][1])\n",
    "    plt.subplot(6,3,i*3+3)\n",
    "    plt.imshow(check_data[1][i][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training transformations (separately for input and gt)\n",
    "training_imtransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         RandFlip(spatial_axis=1, prob=.5),\n",
    "         RandFlip(spatial_axis=0, prob=.5),\n",
    "         RandRotate(range_x=15, prob=0.3, keep_size=True),\n",
    "         ScaleIntensity(),\n",
    "         ToTensor()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "training_gttransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         RandFlip(spatial_axis=1, prob=.5),\n",
    "         RandFlip(spatial_axis=0, prob=.5),\n",
    "         RandRotate(range_x=15, prob=0.3, keep_size=True),\n",
    "         ToTensor(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "         # Lambda(lambda x: x[0,:,:]),\n",
    "         # AddChannel(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "validation_imtransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         ScaleIntensity(),\n",
    "         ToTensor()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "validation_gttransforms = Compose(\n",
    "        [ LoadImage(image_only=True),\n",
    "         AsChannelFirst(),\n",
    "         ToTensor(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "         # Lambda(lambda x: x[0,:,:]),\n",
    "         # AddChannel(),\n",
    "         # Lambda(lambda x: torch.cat([x==255, x==0,x==128], 0))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = ArrayDataset(training_images, training_imtransforms, training_gt, training_gttransforms)\n",
    "training_loader = torch.utils.data.DataLoader(training_ds, batch_size=6, shuffle=True)\n",
    "\n",
    "validation_ds = ArrayDataset(validation_images, validation_imtransforms, validation_gt, validation_gttransforms)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "\n",
    "model_dir = \"/kvh4/optic_disc/models/01_UNet\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = UNet(\n",
    "        dimensions=2,\n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        channels=(32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\") #, get_not_nans=False)\n",
    "\n",
    "# transforms for the output\n",
    "post_trans_1 = Compose([ AddChannel(), Activations(softmax=True)])\n",
    "post_trans_2 = Compose([ Activations(softmax=True), AsDiscrete(threshold_values=True)])\n",
    "\n",
    "loss_function = DiceLoss(softmax = True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_interval = 1\n",
    "# best_metric = -1\n",
    "# best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{10}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in training_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(training_ds) // training_loader.batch_size\n",
    "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        # writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    savepath = os.path.join(model_dir, \"epoch_\"+str(epoch+1)+\".pth\")\n",
    "    print(\"savepath: \", savepath)\n",
    "    torch.save(model.state_dict(), savepath)\n",
    "    print(\"saved model\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in validation_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                # val_outputs = [post_trans_1(i) for i in val_outputs]\n",
    "                val_outputs = post_trans_1(val_outputs[0])\n",
    "                # compute metric for current iteration\n",
    "                value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.item() * len(value)\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            # reset the status for next validation round\n",
    "            # dice_metric.reset()\n",
    "        \n",
    "            \n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f}\".format(\n",
    "                    epoch + 1, metric\n",
    "                )\n",
    "            )\n",
    "            \n",
    "np.save(os.path.join(model_dir, \"epoch_loss.npy\"), epoch_loss_values)\n",
    "np.save(os.path.join(model_dir, \"val_metrics.npy\"), metric_values)\n",
    "\n",
    "\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            # plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            # plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            # plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans_1 = Compose([ AddChannel(), Activations(softmax=True)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs = post_trans_1(val_outputs[0])\n",
    "# compute metric for current iteration\n",
    "val_outputs = val_outputs[None,:]\n",
    "val_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric(y_pred=val_outputs, y=val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = dice_metric(y_pred=val_outputs, y=val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
